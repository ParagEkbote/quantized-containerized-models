# quantized-containerized-models

**quantized-containerized-models** is a project aimed at demonstrating how to deploy AI models inside efficient containerized environments. The repository is designed to help you efficiently serve lightweight, optimized models using modern DevOps practices.

To install cog:

```
sudo curl -o /usr/local/bin/cog -L "https://github.com/replicate/cog/releases/latest/download/cog_$(uname -s)_$(uname -m)"
sudo chmod +x /usr/local/bin/cog
```

## Features

- **Quantization**: Showcases techniques for reducing model size and speeding up inference via quantization.
- **Containerization**: Provides Docker-based solutions for packaging and deploying machine learning models.
- **Python-based**: The project uses Python for model handling and deployment scripts.
- **Open Source**: Licensed under the Apache License 2.0.

## Getting Started

### Prerequisites

- Python 3.x
- Docker



## License

This project is licensed under the [Apache License 2.0](LICENSE).

---

> GitHub: [ParagEkbote/quantized-containerized-models](https://github.com/ParagEkbote/quantized-containerized-models)