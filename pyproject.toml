[project]
name = "quantized-containerized-models"
description = "A project that demonstrates how to deploy AI models with significant improvements, within containerized environments using Cog. Ideal for reproducible, scalable and hardware-efficient inference."
version = "0.3.0"
authors = [{ name = "Parag Ekbote", email = "paragekbote23@gmail.com" }]
readme = "README.md"
license = { text = "Apache 2.0" }
requires-python = ">=3.10"

# ===== Core runtime dependencies =====
dependencies = [
    "torch>=2.1.0",
    "transformers>=4.36.0",
    "diffusers>=0.30.0",
    "pruna>=0.1.1",
    "pillow>=11.3.0",
    "IPython",
    "colorama",
    "unsloth",
    "unsloth_zoo",
    "torchao",
    "python-dotenv==1.1.1",
    "accelerate>=1.8.0",
    "bitsandbytes>=0.45.0",
    "requests>=2.31.0",
    "protobuf>=3.20.0",
    "huggingface-hub[hf-xet]"
]

# ===== Optional dependency groups =====
[project.optional-dependencies]
lint = [
    "black",
    "flake8",
    "isort",
    "ty"
]

test = [
    "pre-commit",
    "pytest"
]

fa_build = [
    "flash-attn",
    "cmake",
    "ninja",
    "wheel"
]

# ===== Packaging (make models discoverable) =====
[tool.setuptools]


[tool.setuptools.packages.find]
where = ["."]
include = ["models*"]

# ===== Pytest settings =====
[tool.pytest.ini_options]
minversion = "8.0"
addopts = "-ra -q"
testpaths = ["tests"]
pythonpath = ["."]
filterwarnings = [
    "ignore::DeprecationWarning",
    "ignore::UserWarning",
]

# ===== Linting/Formatting =====
[tool.ty.rules]
unresolved-import = "ignore"

[tool.black]
line-length = 99
skip-string-normalization = true
target-version = ['py310']

[tool.isort]
profile = "black"
line_length = 99
combine_as_imports = true

[tool.flake8]
max-line-length = 99
extend-ignore = ["D204", "D401", "E203", "W503"]
